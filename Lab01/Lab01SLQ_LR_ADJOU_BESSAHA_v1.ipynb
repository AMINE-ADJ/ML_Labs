{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2CS SIL2-SIQ2 Lab01. Logistic Regression\n",
    "\n",
    "<p style='text-align: right;font-style: italic;'>Designed by: Abdelkrime Aries</p>\n",
    "\n",
    "In this lab, we will learn all about logistic regression:\n",
    "- Linear regression\n",
    "- Binary logistic regression\n",
    "- Multi-class logistic regression\n",
    "- Multi-label logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team:**\n",
    "- **Member 01**: ADJOU AMINE\n",
    "- **Member 02**: BESSAHA SOFIANE\n",
    "- **Group**: SIQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.11.3 (main, Apr 19 2023, 23:54:32) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, timeit\n",
    "from typing          import Tuple, List, Type\n",
    "from collections.abc import Callable\n",
    "\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.24.3', '1.5.3', '3.7.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy             as np\n",
    "import pandas            as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "np.__version__, pd.__version__, matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.linear_model    import SGDClassifier\n",
    "from sklearn.multiclass      import OneVsRestClassifier\n",
    "from sklearn.multiclass      import OneVsOneClassifier\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from sklearn.metrics         import classification_report\n",
    "from sklearn.metrics         import log_loss\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is used to filter warnings concerning convergence\n",
    "# In general, when the maximum number of iterations is not suffisant to converge\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Algorithms implementation\n",
    "\n",
    "In this section, we will try to implement all forms of linear/logistic regression. In fact, those forms are similar and use almost the same algorithms. For example, multi-label LR is actually binary regression with multiple outputs. \n",
    "\n",
    "\n",
    "**>> Try to use \"numpy\" which will save a lot of time and effort**\n",
    "\n",
    "### I.1. Prediction functions\n",
    "\n",
    "We want to implement all prediction functions used for linear regression, binary logistic regression and Maximum entropy (Logistic regression with softmax).\n",
    "\n",
    "#### I.1.1. Linear combination\n",
    "\n",
    "Given an input:\n",
    "- $X[M, N]$ a matrix of $M$ samples and $N$ features\n",
    "\n",
    "and some parameters ($theta_0$ is already embedded as the first parameter):\n",
    "- $\\theta[N]$: in case of binary classification \n",
    "- $\\theta[N, L]$: in case of multi-class classification. $L$ is the number of classes/labels.\n",
    "\n",
    "calculate the output: \n",
    "- $Z[M]$: each sample has one output (binary)\n",
    "- $Z[M, L]$: each sample has $L$ outputs (multiple)\n",
    "\n",
    "each class/label $c$ (in case of binary classification, there is only one label) has an output:\n",
    "$$Z_c = \\sum\\limits_{j=0}^{N} \\theta_{(c, j)} X_j | X_0 = 1 $$\n",
    "\n",
    "A more general form: \n",
    "$$Z = zfn(X, \\theta) = X \\cdot \\theta$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1. , 1.7, 2.4]),\n",
       " array([[0. , 0. , 0. ],\n",
       "        [0.5, 0.1, 0.6],\n",
       "        [0.2, 0.3, 0. ],\n",
       "        [0.7, 0.4, 0.6]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Linear combination\n",
    "def zfn(X: np.ndarray, Theta: np.ndarray) -> np.ndarray: \n",
    "    return np.dot(X,Theta)\n",
    "\n",
    "#=====================================================================\n",
    "# UNIT TEST\n",
    "#=====================================================================\n",
    "# Result: \n",
    "# (array([1. , 1.7, 2.4]),\n",
    "#  array([[0. , 0. , 0. ],\n",
    "#         [0.5, 0.1, 0.6],\n",
    "#         [0.2, 0.3, 0. ],\n",
    "#         [0.7, 0.4, 0.6]]))\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "X_t     = np.array([[1., 100.], \n",
    "                    [1., 200.], \n",
    "                    [1., 300.]])\n",
    "Theta_t = np.array([0.3, 0.007])\n",
    "\n",
    "X_tL = np.array([[0., 0.], \n",
    "                 [1., 0.], \n",
    "                 [0., 1.], \n",
    "                 [1., 1.]]) # 4 samples, 2 features\n",
    "Theta_tL = np.array([[0.5, 0.1, 0.6],\n",
    "                     [0.2, 0.3, 0.0]]) # 2 features, 3 classes\n",
    "# binary, multiple\n",
    "zfn(X_t, Theta_t), zfn(X_tL, Theta_tL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.1.2. Logistic function\n",
    "\n",
    "Given the linear combination:\n",
    "- $Z[M]$: each sample has one output (binary)\n",
    "- $Z[M, L]$: each sample has $L$ outputs (multiple)\n",
    "\n",
    "We generate prediction probabilities:\n",
    "- $H[M]$: each sample has one output (binary)\n",
    "- $H[M, L]$: each sample has $L$ outputs (multiple)\n",
    "\n",
    "Using the logistic function:\n",
    "$$H = \\sigma(Z) = \\frac{1}{1+e^{-Z}}$$\n",
    "\n",
    "**>> Using numpy arrays, this function works for vectors and matrices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.73105858, 0.84553473, 0.9168273 ]),\n",
       " array([[0.5       , 0.5       , 0.5       ],\n",
       "        [0.62245933, 0.52497919, 0.64565631],\n",
       "        [0.549834  , 0.57444252, 0.5       ],\n",
       "        [0.66818777, 0.59868766, 0.64565631]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Logistic function\n",
    "def sgfn(Z: 'np.ndarray[M, L]') -> 'np.ndarray[M, L]': \n",
    "    \n",
    "    return 1 / ( 1 + np.exp(- Z) )\n",
    "\n",
    "#=====================================================================\n",
    "# UNIT TEST\n",
    "#=====================================================================\n",
    "# Result: \n",
    "# (array([0.73105858, 0.84553473, 0.9168273 ]),\n",
    "#  array([[0.5       , 0.5       , 0.5       ],\n",
    "#         [0.62245933, 0.52497919, 0.64565631],\n",
    "#         [0.549834  , 0.57444252, 0.5       ],\n",
    "#         [0.66818777, 0.59868766, 0.64565631]]))\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "Z_t = np.array([1. , 1.7, 2.4])\n",
    "Z_tL = np.array([[0. , 0. , 0. ],\n",
    "                 [0.5, 0.1, 0.6],\n",
    "                 [0.2, 0.3, 0. ],\n",
    "                 [0.7, 0.4, 0.6]])\n",
    "\n",
    "# binary, multiple\n",
    "sgfn(Z_t), sgfn(Z_tL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.1.3. Softmax function\n",
    "\n",
    "Given the linear combination:\n",
    "- $Z[M, L]$: each sample has $L$ outputs (multiple)\n",
    "\n",
    "We generate predictions:\n",
    "- $H[M, L]$: each sample has $L$ outputs (multiple)\n",
    "\n",
    "Using the softmax function:\n",
    "$$H = softmax(Z)=\\frac{e^Z}{\\sum\\limits_{k=1}^{L} e^{Z_k}}$$\n",
    "\n",
    "Basically:\n",
    "- Calculate $H' = e^Z$\n",
    "- Then divide $H'$ by the vector $H'$ summed over colums\n",
    "- numpy automatically transforms a vector $V[M, 1]$ into $V[M]$. So, you have to force a vertical vector using **reshape(-1, 1)**.\n",
    "- The sum of probabilities in each row must equal 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.36029662, 0.24151404, 0.39818934],\n",
       "       [0.34200877, 0.37797814, 0.28001309],\n",
       "       [0.37797814, 0.28001309, 0.34200877]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Softmax function\n",
    "def softmaxfn(Z: np.ndarray) -> np.ndarray:\n",
    "    H1 = np.exp(Z)\n",
    "    Sum_of_cols = np.sum(H1, axis = 1).reshape(-1,1)\n",
    "    return H1 / Sum_of_cols\n",
    "\n",
    "#=====================================================================\n",
    "# UNIT TEST\n",
    "#=====================================================================\n",
    "# Result: \n",
    "# array([[0.33333333, 0.33333333, 0.33333333],\n",
    "#        [0.36029662, 0.24151404, 0.39818934],\n",
    "#        [0.34200877, 0.37797814, 0.28001309],\n",
    "#        [0.37797814, 0.28001309, 0.34200877]])\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "Z_tL = np.array([[0. , 0. , 0. ],\n",
    "                 [0.5, 0.1, 0.6],\n",
    "                 [0.2, 0.3, 0. ],\n",
    "                 [0.7, 0.4, 0.6]])\n",
    "softmaxfn(Z_tL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2. Cost functions\n",
    "\n",
    "We want to implement these cost functions:\n",
    "- Mean Square Error (MSE): for linear regression\n",
    "- Binary Cross Entropy (BCE): for binary logistic regression and multi-label logistic regression\n",
    "- Cross Entropy (CE): for maximum entropy (MaxEnt) algorithm (multi-class logistic regression)\n",
    "\n",
    "\n",
    "#### I.2.1. Mean Square Error (MSE)\n",
    "\n",
    "Given the estimated outputs $H[M]$, calculate the error based on the real outputs $Y[M]$.\n",
    "\n",
    "$$J = MSE(Y, H) = \\frac{1}{2M} \\sum\\limits_{i=1}^{M} (Y - H)^2$$\n",
    "\n",
    "**>> This is used for linear regression which is applicable only on one output per sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016666666666666673"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: MSE cost function\n",
    "def MSEfn(Y: 'np.ndarray[M]', \n",
    "        H: 'np.ndarray[M]') -> float:\n",
    "    M = Y.shape[0]\n",
    "    return np.sum(( Y - H ) **2) / ( 2 * M )\n",
    "\n",
    "#=====================================================================\n",
    "# UNIT TEST\n",
    "#=====================================================================\n",
    "# Result:\n",
    "# 0.016666666666666673\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "H_t = np.array([1. , 1.7, 2.4])\n",
    "Y_t = np.array([1., 2., 2.5])\n",
    "MSEfn(Y_t, H_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.2.2. Binary Cross Entropy (BCE)\n",
    "\n",
    "Given the output probabilities:\n",
    "- $H[M]$: each sample has one output (binary)\n",
    "- $H[M, L]$: each sample has $L$ outputs (multi-label)\n",
    "\n",
    "and the real classes:\n",
    "- $Y[M]$: each sample has one output (binary)\n",
    "- $Y[M, L]$: each sample has $L$ outputs (multi-label)\n",
    "\n",
    "The BCE loss for one sample is:\n",
    "$$BCE(Y^{(i)}, H^{(i)})\n",
    "= \\begin{cases}\n",
    "- \\log(H^{(i)}) & \\text{ si } Y^{(i)} = 1\\\\ \n",
    "- \\log(1 - H^{(i)})  & \\text{ si } Y^{(i)} = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "Since $Y^{(i)} \\in \\{0, 1\\}$, then: \n",
    "\n",
    "$$ BCE(Y^{(i)}, H^{(i)}) = - Y^{(i)} \\log(H^{(i)}) - (1- Y^{(i)}) \\log(1 - H^{(i)}) $$\n",
    "\n",
    "Then, the loss function will be:\n",
    "$$J = BCE(Y, H) = \\frac{-1}{M} \\sum\\limits_{i=1}^{M} [Y^{(i)} \\log(H^{(i)}) + (1- Y^{(i)}) \\log(1 - H^{(i)})]$$\n",
    "\n",
    "**>> practically, a little value epsilon is added into the log to avoid log(0)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7559612797265517,\n",
       " 0.7559612499514038,\n",
       " 0.7112278056068634,\n",
       " 0.7112277848173427)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: BCE loss function\n",
    "def BCEfn(Y  : 'np.ndarray[M,L]', \n",
    "        H  : 'np.ndarray[M,L]', \n",
    "        eps: float = 1e-8   ) -> float: \n",
    "    return - np.mean(Y * np.log(H + eps) + (1 - Y) * np.log(1 - H + eps))\n",
    "\n",
    "#=====================================================================\n",
    "# UNIT TEST\n",
    "#=====================================================================\n",
    "# Result:\n",
    "# (0.7559612797265517,\n",
    "#  0.7559612499514038,\n",
    "#  0.7112278056068634,\n",
    "#  0.7112277848173427)\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "Y_t = np.array([1., 0., 1.])\n",
    "H_t = np.array([0.73105858, 0.84553473, 0.9168273 ])\n",
    "\n",
    "Y_tL = np.array([[1, 0, 1],\n",
    "                 [1, 1, 0],\n",
    "                 [1, 1, 1],\n",
    "                 [0, 0, 1]]) # multilabel\n",
    "H_tL = np.array([[0.5       , 0.5       , 0.5       ],\n",
    "                 [0.62245933, 0.52497919, 0.64565631],\n",
    "                 [0.549834  , 0.57444252, 0.5       ],\n",
    "                 [0.66818777, 0.59868766, 0.64565631]])\n",
    "\n",
    "BCEfn(Y_t, H_t, eps=0), BCEfn(Y_t, H_t), BCEfn(Y_tL, H_tL, eps=0), BCEfn(Y_tL, H_tL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.2.3. Cross Entropy (CE)\n",
    "\n",
    "Given the output probabilities:\n",
    "- $H[M, L]$: each sample has $L$ outputs (multi-class)\n",
    "\n",
    "and the real classes:\n",
    "- $Y[M, L]$: each sample has $L$ outputs (multi-class)\n",
    "\n",
    "$$J = CE(H, Y) = \\frac{-1}{M} \\sum\\limits_{i=1}^{M} \\sum\\limits_{c=1}^{L} Y^{(i)}_c \\log(H^{(i)}_c)$$\n",
    "\n",
    "**>> HINT: sum over classes (column), mean over samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1913194530574498"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: CE loss function\n",
    "def CEfn(Y: np.ndarray, H: np.ndarray) -> np.ndarray:\n",
    "    return -np.mean(np.sum(Y * np.log(H), axis=1))\n",
    "\n",
    "#=====================================================================\n",
    "# UNIT TEST\n",
    "#=====================================================================\n",
    "# Result:\n",
    "# 1.1913194530574498\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "Y_tL = np.array([[1,0,0], \n",
    "                 [0,1,0], \n",
    "                 [0,0,1], \n",
    "                 [1,0,0]])\n",
    "H_tL = np.array([[0.33333333, 0.33333333, 0.33333333],\n",
    "                 [0.36029662, 0.24151404, 0.39818934],\n",
    "                 [0.34200877, 0.37797814, 0.28001309],\n",
    "                 [0.37797814, 0.28001309, 0.34200877]])\n",
    "\n",
    "CEfn(Y_tL, H_tL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3. Gradients\n",
    "\n",
    "We want to implement these cost functions' gradients:\n",
    "- dMSE: for linear regression\n",
    "- dBCE: for binary logistic regression (the same as dMSE) and multi-label logistic regression (a little different)\n",
    "- dCE: for maximum entropy (MaxEnt) algorithm (multi-class logistic regression)\n",
    "\n",
    "**>> Good news: gradients function is the same**\n",
    "\n",
    "\n",
    "Given the input:\n",
    "- $X[M, N]$ a matrix of $M$ samples and $N$ features\n",
    "\n",
    "the real output values:\n",
    "- $Y[M]$: each sample has one output\n",
    "- $Y[M, L]$: each sample has $L$ outputs\n",
    "\n",
    "and the estimated output:\n",
    "- $H[M]$: each sample has one estimated output\n",
    "- $H[M, L]$: each sample has $L$ estimated outputs\n",
    "\n",
    "calculate the gradients: \n",
    "- $\\frac{\\partial J}{\\partial \\theta}[N]$: each feature has one gradient\n",
    "- $\\frac{\\partial J}{\\partial \\theta}[N, L]$: each feature has $L$ gradients\n",
    "\n",
    "The gradients are calculated as (matrix form):\n",
    "$$\\frac{\\partial J}{\\partial \\theta} = \\frac{1}{M} (X^T \\cdot (H - Y))$$\n",
    "\n",
    "---\n",
    "A BORING CALCULATION (MSE)\n",
    "\n",
    "$$\\frac{\\partial MSE}{\\partial \\theta_j} \n",
    "= \\frac{\\partial }{\\partial \\theta_j} \\frac{1}{2M} \\sum\\limits_{i=1}^{M} (Y^{(i)} - H^{(i)})^2 \n",
    "= \\frac{1}{2M} \\sum\\limits_{i=1}^{M} [\\frac{\\partial }{\\partial \\theta_j} (Y^{(i)} - H^{(i)})^2]\n",
    "= \\frac{1}{2M} \\sum\\limits_{i=1}^{M} [-2 (Y^{(i)} - H^{(i)}) \\frac{\\partial }{\\partial \\theta_j} H^{(i)}]\n",
    "$$\n",
    "\n",
    "$$\\frac{\\partial MSE}{\\partial \\theta_j}\n",
    "= \\frac{1}{M} \\sum\\limits_{i=1}^{M} [(H^{(i)} - Y^{(i)}) \\frac{\\partial }{\\partial \\theta_j} \\sum\\limits_{k=0}^{N} \\theta_k X_k^{(i)}]\n",
    "= \\frac{1}{M} \\sum\\limits_{i=1}^{M} [(H^{(i)} - Y^{(i)}) \\frac{\\partial }{\\partial \\theta_j} \\theta_j X_j^{(i)}]\n",
    "$$\n",
    "$$\\frac{\\partial MSE}{\\partial \\theta_j} = \\frac{1}{M} \\sum\\limits_{i=1}^{M} (H^{(i)} - Y^{(i)}) X_j^{(i)}$$\n",
    "\n",
    "---\n",
    "A BORING CALCULATION (BCE)\n",
    "\n",
    "$$\\frac{\\partial BCE}{\\partial \\theta_j} \n",
    "= \\frac{-1}{M} \\sum\\limits_{i=1}^{M} \\frac{\\partial}{\\partial \\theta_j} [Y^{(i)} \\log(H^{(i)}) + (1- Y^{(i)}) \\log(1 - H^{(i)})]\n",
    "$$\n",
    "\n",
    "$$\\frac{\\partial BCE}{\\partial \\theta_j} \n",
    "= \\frac{-1}{M} \\sum\\limits_{i=1}^{M} [ Y^{(i)} \\frac{\\partial}{\\partial \\theta_j} \\log(H^{(i)}) + (1- Y^{(i)}) \\frac{\\partial}{\\partial \\theta_j}\\log(1 - H^{(i)})]\n",
    "$$\n",
    "\n",
    "$$\\frac{\\partial BCE}{\\partial \\theta_j} \n",
    "= \\frac{-1}{M} \\sum\\limits_{i=1}^{M} [ Y^{(i)} \\frac{1}{H^{(i)}} \\frac{\\partial}{\\partial \\theta_j} H^{(i)} + (1- Y^{(i)}) \\frac{-1}{1-H^{(i)}} \\frac{\\partial}{\\partial \\theta_j} H^{(i)})]\n",
    "= \\frac{-1}{M} \\sum\\limits_{i=1}^{M} \\frac{Y^{(i)}-H^{(i)}}{H^{(i)}(1-H^{(i)})} \\frac{\\partial}{\\partial \\theta_j} H^{(i)}\n",
    "$$\n",
    "\n",
    "$$\\frac{\\partial H^{(i)}}{\\partial \\theta_j} \n",
    "= \\frac{\\partial \\sigma(Z^{(i)})}{\\partial Z^{(i)}} \\frac{\\partial Z^{(i)}}{\\partial \\theta_j} \n",
    "= [\\sigma(Z^{(i)}) (1-\\sigma(Z^{(i)}))]\\frac{\\partial}{\\partial \\theta_j} \\sum\\limits_{k=0}^{N} \\theta_k X_k^{(i)}  \n",
    "= H^{(i)} (1-H^{(i)})  X_j^{(i)}\n",
    "$$\n",
    "\n",
    "$$\\frac{\\partial BCE}{\\partial \\theta_j} \n",
    "= \\frac{-1}{M} \\sum\\limits_{i=1}^{M} \\frac{Y^{(i)}-H^{(i)}}{H^{(i)}(1-H^{(i)})} [H^{(i)} (1-H^{(i)}) X_j^{(i)}]\n",
    "$$\n",
    "\n",
    "$$\\frac{\\partial BCE}{\\partial \\theta_j} = \\frac{1}{M} \\sum\\limits_{i=1}^{M} (H^{(i)} - Y^{(i)}) X_j^{(i)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Gradients\n",
    "def dJfn(X: np.ndarray, H: np.ndarray, Y: np.ndarray) -> np.ndarray:\n",
    "    return  None\n",
    "\n",
    "#=====================================================================\n",
    "# UNIT TEST\n",
    "#=====================================================================\n",
    "# Result: \n",
    "# (array([ 0.13333333, 30.        ]),\n",
    "#  array([[ 0.06543131,  0.11961822, -0.18504953],\n",
    "#         [ 0.07000327, -0.16449781,  0.09449454]]))\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "X_t = np.array([[1., 100.], \n",
    "                [1., 200.], \n",
    "                [1., 300.]])\n",
    "H_t = np.array([1. , 1.7, 2.4])\n",
    "Y_t = np.array([1., 2., 2.5])\n",
    "\n",
    "X_tL = np.array([[0., 0.], [1., 0.], [0., 1.], [1., 1.]])\n",
    "H_tL = np.array([[0.33333333, 0.33333333, 0.33333333],\n",
    "                 [0.36029662, 0.24151404, 0.39818934],\n",
    "                 [0.34200877, 0.37797814, 0.28001309],\n",
    "                 [0.37797814, 0.28001309, 0.34200877]])\n",
    "Y_tL = np.array([[1,0,0], [0,1,0], [0,0,1], [1,0,0]])\n",
    "\n",
    "\n",
    "dJfn(X_t, Y_t, H_t), dJfn(X_tL, Y_tL, H_tL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4. Final product\n",
    "\n",
    "**>> Nothing to code here**\n",
    "\n",
    "This section is to show how all the previous algorithms are merged into one usefull program. \n",
    "So, we will use all the previously implemented functions, add some others and implement a class which is easy to use.\n",
    "\n",
    "#### I.4.1. Gradient descent \n",
    "\n",
    "This is the simplest version of gradient descent. It iterates until it reaches the maximum iterations.\n",
    "It takes estimation function, cost function and gradient function as arguments so we can used it for different problems (linear regression, binary logistic regression, etc.). Also known as polymorphism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m Theta_t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m1.\u001b[39m])\n\u001b[1;32m     44\u001b[0m Y_t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 46\u001b[0m Theta_new, J_hist \u001b[38;5;241m=\u001b[39m GDfn(X_t, Y_t, Theta_t, IT\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     48\u001b[0m Theta_new, J_hist\n",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m, in \u001b[0;36mGDfn\u001b[0;34m(X, Y, Theta, IT, alpha, H_fn, J_fn, dJ_fn)\u001b[0m\n\u001b[1;32m     18\u001b[0m     dJ \u001b[38;5;241m=\u001b[39m dJ_fn(X, H, Y)  \u001b[38;5;66;03m# gradients\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     costs\u001b[38;5;241m.\u001b[39mappend(J) \u001b[38;5;66;03m# add cost into history\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     Theta \u001b[38;5;241m=\u001b[39m Theta \u001b[38;5;241m-\u001b[39m alpha \u001b[38;5;241m*\u001b[39m dJ \u001b[38;5;66;03m# update parameters\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Theta, costs\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# Gradient descent. By default, it is linear regression\n",
    "def GDfn (X    : 'np.ndarray[M, N]', # Input M samples, N features (obligatory)\n",
    "          Y    : 'np.ndarray[M, L]', # Output M samples, L classes (obligatory)\n",
    "          Theta: 'np.ndarray[N, L]', # Parameters (obligatory)\n",
    "          IT   : int      = 100    , # Maximum number of iterations\n",
    "          alpha: float    = 0.01   , # Learning rate\n",
    "          H_fn : Callable = zfn    , # Estimation function\n",
    "          J_fn : Callable = MSEfn  , # Cost function\n",
    "          dJ_fn: Callable = dJfn     # Gradient function\n",
    "         ) -> Tuple[List[np.ndarray], List[float]]: \n",
    "     \n",
    "    costs  = []           # costs history\n",
    "    Theta  = Theta.copy() # make a copy of the original parameters\n",
    "    \n",
    "    for it in range(IT):\n",
    "        H  = H_fn (X, Theta) # estimation\n",
    "        J  = J_fn (Y, H)     # cost\n",
    "        dJ = dJ_fn(X, H, Y)  # gradients\n",
    "        \n",
    "        costs.append(J) # add cost into history\n",
    "        Theta = Theta - alpha * dJ # update parameters\n",
    "         \n",
    "    return Theta, costs\n",
    "\n",
    "#=====================================================================\n",
    "# UNIT TEST\n",
    "#=====================================================================\n",
    "# Result:\n",
    "# (array([0.86298175, 0.58991304, 0.96329937]),\n",
    "#  [6.3375,\n",
    "#   5.32767996484375,\n",
    "#   4.48068435059748,\n",
    "#   3.7702582684901684,\n",
    "#   3.174380343989813])\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "X_t = np.array([\n",
    "    [1, 1, 0.2],\n",
    "    [1, 2, 0.1],\n",
    "    [1, 3, 0.4],\n",
    "    [1, 4, 0.3]\n",
    "])\n",
    "Theta_t = np.array([1., 1., 1.])\n",
    "Y_t = np.array([1, 0, 1, 0])\n",
    "\n",
    "Theta_new, J_hist = GDfn(X_t, Y_t, Theta_t, IT=5)\n",
    "\n",
    "Theta_new, J_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.4.2. Data preparation functions \n",
    "\n",
    "The function **norm** normalizes the input $X' = \\frac{X-\\mu}{\\sigma}$:\n",
    "- in case of training data $X_{train}$, the mean and standard deviation are calculated on this data\n",
    "- in case of test data $X_{test}$, the mean and standard deviation must be those calculated over $X_{train}$ (passed as arguments)\n",
    "\n",
    "The function **prepare** returns a prepared data:\n",
    "- if norm=True: data will be normalized; otherwise it will be the same\n",
    "- if bias=True: a column of 1s will be added into $X$ (it is like adding $\\theta_0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize X based on the \n",
    "def normfn(X, mean=None, std=None): \n",
    "    if (mean is None) or (std is None): \n",
    "        mean = np.mean(X, axis=0)\n",
    "        std = np.std(X, axis=0)\n",
    "    X_norm = np.where(std==0, X, (X - mean)/std)\n",
    "    return X_norm, mean, std\n",
    "\n",
    "def preparefn(X, norm=True, bias=True, mean=None, std=None): \n",
    "    X_pre = X.copy()\n",
    "    if norm: \n",
    "        X_pre, mean, std = normfn(X_pre, mean=mean, std=std)\n",
    "    if bias:\n",
    "        X_pre = np.append(np.ones((X_pre.shape[0],1)), X_pre ,axis=1)\n",
    "    return X_pre, mean, std\n",
    "\n",
    "#=====================================================================\n",
    "# UNIT TEST\n",
    "#=====================================================================\n",
    "# Result:\n",
    "# ((array([[ 1.        , -1.22474487, -0.26726124],\n",
    "#          [ 1.        ,  0.        , -1.06904497],\n",
    "#          [ 1.        ,  1.22474487,  1.33630621]]),\n",
    "#   array([2.        , 0.23333333]),\n",
    "#   array([0.81649658, 0.12472191])),\n",
    "#  (array([[-0.25,  1.  ],\n",
    "#          [ 0.25,  0.  ],\n",
    "#          [ 0.75,  3.  ]]),\n",
    "#   array([1.5, 0.1]),\n",
    "#   array([2. , 0.1])))\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "X_t = np.array([[1, 0.2],\n",
    "                [2, 0.1],\n",
    "                [3, 0.4]])\n",
    "\n",
    "preparefn(X_t), preparefn(X_t, bias=False, mean=np.array([1.5, 0.1]), std=np.array([2, 0.1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.4.3.  Missing functions \n",
    "\n",
    "These are functions which must be implemented before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote(H: np.ndarray) -> np.ndarray:\n",
    "    res = np.zeros(H.shape)\n",
    "    res[range(len(H)), H.argmax(axis=1)] = 1\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.4.4.  Regression class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(object):\n",
    "    \n",
    "    def __init__(self, norm=True, bias=True, type='linear'): \n",
    "        self.norm  = norm\n",
    "        self.bias  = bias\n",
    "        \n",
    "        # by default linear regression\n",
    "        self.Hfn : Callable = zfn   # Estimation function\n",
    "        self.Yfn : Callable = zfn   # Prediction function\n",
    "        self.Jfn : Callable = MSEfn # Cost function\n",
    "        self.dJfn: Callable = dJfn  # Gradient function\n",
    "            \n",
    "        if type in ['binary', 'multilabel']:\n",
    "            self.Hfn = lambda X, Theta : sgfn(zfn(X, Theta))\n",
    "            self.Yfn = lambda X, Theta : (self.Hfn(X, Theta) >= 0.5).astype(int)\n",
    "            self.Jfn = BCEfn\n",
    "        elif type == 'multiclass':\n",
    "            self.Hfn = lambda X, Theta : softmaxfn(zfn(X, Theta))\n",
    "            self.Yfn = lambda X, Theta : vote(self.Hfn(X, Theta))\n",
    "            self.Jfn = CEfn\n",
    "            \n",
    "    \n",
    "    def fit(self, X, Y, max_iter=100, alpha=.01) -> List[float]: \n",
    "        X_pre, self.mean, self.std = preparefn(X, norm=self.norm, bias=self.bias)\n",
    "        if len(Y.shape) > 1:\n",
    "            Theta = np.zeros((X_pre.shape[1], Y.shape[1]))\n",
    "        else:\n",
    "            Theta = np.zeros(X_pre.shape[1])\n",
    "        self.Theta, costs = GDfn(X_pre, Y, Theta, IT=max_iter, alpha=alpha)\n",
    "        return costs\n",
    "        \n",
    "        \n",
    "    # Predictions\n",
    "    # if prob=True return probbilities\n",
    "    # else return labels\n",
    "    def predict(self, X, prob=True):\n",
    "        X_pre, _, _ = preparefn(X, norm=self.norm, bias=self.bias, mean=self.mean, std=self.std)\n",
    "        if prob:\n",
    "            return self.Hfn(X_pre, self.Theta)\n",
    "        return self.Yfn(X_pre, self.Theta)\n",
    "\n",
    "\n",
    "#=====================================================================\n",
    "# UNIT TEST\n",
    "#=====================================================================\n",
    "# Result: \n",
    "# array([[1., 0., 0.],\n",
    "#        [0., 1., 0.],\n",
    "#        [0., 1., 0.],\n",
    "#        [0., 0., 1.]])\n",
    "#---------------------------------------------------------------------\n",
    "X_tn = np.array([[0., 0.], [1., 0.], [0., 1.], [1., 1.]])\n",
    "Y_tn = np.array([[1,0,0], [0,1,0], [0,0,1], [1,0,0]])\n",
    "\n",
    "X_testn = np.array([[2., 2.], [1., 0.], [1., -1.], [2., 5.]])\n",
    "\n",
    "maxent = Regression(type='multiclass')\n",
    "_ = maxent.fit(X_tn, Y_tn)\n",
    "maxent.predict(X_testn, prob=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Application and Analysis\n",
    "\n",
    "In this section, we will test different concepts by running an experiment, formulating a hypothesis and trying to justify it. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = pd.read_csv('data/grades.csv')\n",
    "\n",
    "# Extraction des caractéristiques \n",
    "Xgrades = grades.iloc[:, :-1].values # Premières colonnes \n",
    "Ygrades = grades.iloc[:,  -1].values # Dernière colonne \n",
    "\n",
    "Xgrades_norm = Xgrades/20 # Nous savons le maximum\n",
    "\n",
    "grades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/kukuroo3/body-performance-data\n",
    "body = pd.read_csv('data/bodyPerformance.csv')\n",
    "body['gender'] = (body['gender'] == 'M').astype(int)\n",
    "body.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xbody = body.iloc[:, :-1].values # First columns\n",
    "Ybody = body.iloc[:,  -1].values # Last column  \n",
    "\n",
    "Xbody_train, Xbody_test, Ybody_train, Ybody_test = train_test_split(Xbody, Ybody, \n",
    "                                                                    test_size   =0.2, # 20% for test\n",
    "                                                                    random_state=0, \n",
    "                                                                    stratify    =Ybody) # stratification\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "Xbody_train = scaler.fit_transform(Xbody_train)\n",
    "Xbody_test  = scaler.transform(Xbody_test)\n",
    "\n",
    "Xbody_train.shape, Xbody_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1. Binary Ligistic Regression\n",
    "\n",
    "We want to test the pupose of:\n",
    "- Bias parameter\n",
    "- Data normalization\n",
    "- Learning rate\n",
    "\n",
    "So, we run a series of experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will be used to draw a decision boundary given a model\n",
    "# model: binary clasification model\n",
    "# ax: an object of type matplotlib.axes.Axes; the axes on which we will draw\n",
    "# xrange: a list of points on the X axis (the first feature)\n",
    "# yrange: a list of points on the Y axis (the second feature)\n",
    "# color: the color of the decision boundary\n",
    "# label: the label of the decision boundary\n",
    "def draw2D(model, ax, xrange, yrange, color='red', label=''):\n",
    "    # Create a matrix of (xrange X yrange): our drawing map\n",
    "    XX   = [[[xr, yr] for xr in xrange] for yr in yrange]\n",
    "    # Represent it as a matrix [(xrange X yrange)/2 samples, 2 features]\n",
    "    XX   = np.array(XX).reshape(-1, 2)\n",
    "    # Predict the probabilities (estimation) et retransform them into our map (xrange X yrange)\n",
    "    grid = model.predict(XX).reshape(len(xrange), len(yrange))\n",
    "    # Draw the lines which cross the value 0.5\n",
    "    cs   = ax.contour(xrange, yrange, grid, colors=[color], linewidths=(1), linestyles=('-'),levels=[0.5])\n",
    "    # Assign the label to the boundary\n",
    "#     plt.clabel(cs, inline=1, fontsize=10)\n",
    "#     cs.collections[0].set_label(label)\n",
    "    fmt = {cs.levels[0]: label}\n",
    "    ax.clabel(cs, cs.levels, inline=True, fmt=fmt, fontsize=14)\n",
    "    \n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.1.1. Bias\n",
    "\n",
    "We want to test what the bias really does (why it is useful) \n",
    "To this end, we took a linearly separated problem: a student is admitted if the average of the grades is higher or equals 10.\n",
    "\n",
    "Because the results can be plotted, we will validate the models visually.\n",
    "For this, we trained two models:\n",
    "- **Plain**: without a bias\n",
    "- **Bias**: with a bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "Xgrades_train = Xgrades_norm[:80, :]\n",
    "Xgrades_test  = Xgrades_norm[80:, :]\n",
    "Ygrades_train = Ygrades[:80   ]\n",
    "Ygrades_test  = Ygrades[80:   ]\n",
    "\n",
    "yes_train = Ygrades_train == 1\n",
    "yes_test  = Ygrades_test  == 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.scatter(Xgrades_train[yes_train, 0], \n",
    "           Xgrades_train[yes_train, 1], \n",
    "           color='green', marker='o', label='Admitted (train)')\n",
    "ax.scatter(Xgrades_train[~yes_train, 0], \n",
    "           Xgrades_train[~yes_train, 1], \n",
    "           color='green', marker='x', label='Failed (train)')\n",
    "ax.scatter(Xgrades_test[yes_test, 0], \n",
    "           Xgrades_test[yes_test, 1], \n",
    "           color='red', marker='o', label='Admitted (test)')\n",
    "ax.scatter(Xgrades_test[~yes_test, 0], \n",
    "           Xgrades_test[~yes_test, 1], \n",
    "           color='red', marker='x', label='Failed (test)')\n",
    "\n",
    "\n",
    "\n",
    "# Create grades space: btween 0 and 1 (normalized) with a resolution of 50\n",
    "xrange = np.linspace(0, 1, 50) # Grade 1\n",
    "yrange = np.linspace(0, 1, 50) # Grade 2\n",
    "\n",
    "# Dessiner la ligne de séparation dans une régression linéaire\n",
    "LR_plain = LogisticRegression(penalty=None, fit_intercept=False)\n",
    "LR_plain.fit(Xgrades_train, Ygrades_train)\n",
    "draw2D(LR_plain, ax, xrange, yrange, label='Plain', color='blue')\n",
    "\n",
    "LR_bias = LogisticRegression(penalty=None)\n",
    "LR_bias.fit(Xgrades_train, Ygrades_train)\n",
    "draw2D(LR_bias, ax, xrange, yrange, label='Bias', color='blue')\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Grade 1')\n",
    "plt.ylabel('Grade 2')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyze the results**\n",
    "\n",
    "1. Describe the results (what do you notice?)\n",
    "1. Discuss the effect of bias in this particular example (How it effects the decision boundary)\n",
    "\n",
    "**Answers**\n",
    "\n",
    "1. ...\n",
    "1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.1.2. Normalization\n",
    "\n",
    "We want to test if normalizing data affects model training. \n",
    "To this end, we want to test two aspects:\n",
    "1. Convergence speed\n",
    "1. Convergence quality\n",
    "\n",
    "This is why we trained two models: One on the original data and another on the normalized data. Then, we plotted the cost history according to the iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use SGDClassifier instead of LogisticRegression\n",
    "# Because LogisticRegression does not permit learning rate definition\n",
    "# we will use \"partial_fit\" instead of \"fit\" which is a mini-batch implementation\n",
    "# but, we pass all the dataset\n",
    "\n",
    "ALPHA = 0.01\n",
    "ITMAX = 200\n",
    "\n",
    "LRbin_orig = SGDClassifier(penalty=None, \n",
    "                           warm_start=True, \n",
    "                           loss='log_loss', \n",
    "                           learning_rate='constant', \n",
    "                           eta0=ALPHA,\n",
    "                           shuffle=False\n",
    "                          )\n",
    "LRbin_norm = SGDClassifier(penalty=None, \n",
    "                           warm_start=True, \n",
    "                           loss='log_loss', \n",
    "                           learning_rate='constant', \n",
    "                           eta0=ALPHA,\n",
    "                           shuffle=False\n",
    "                          )\n",
    "\n",
    "classes = np.unique(Ygrades)\n",
    "costs_orig = []\n",
    "costs_norm = []\n",
    "\n",
    "for it in range(ITMAX):\n",
    "    LRbin_orig.partial_fit(Xgrades,      Ygrades, classes=classes)\n",
    "    LRbin_norm.partial_fit(Xgrades_norm, Ygrades, classes=classes)\n",
    "    \n",
    "    costs_orig.append(log_loss(Ygrades, LRbin_orig.predict(Xgrades     )))\n",
    "    costs_norm.append(log_loss(Ygrades, LRbin_norm.predict(Xgrades_norm)))\n",
    "\n",
    "# Visualization\n",
    "plt.plot(costs_orig, label = 'Original')\n",
    "plt.plot(costs_norm  , label = 'Normalized')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost')\n",
    "plt.legend()\n",
    "#plt.autoscale()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyze the results**\n",
    "\n",
    "We note that normalized-data-based model converge faster and better than the original-data-based one in term of iterations. Faster = it reaches its optimal point where it cannot enhance the error more quickly. Better: the error when it converges is less.\n",
    "\n",
    "1. Why faster? (explain how normalization can effect speed)\n",
    "1. Why better? (explain how normalization can effect quality)\n",
    "\n",
    "**Answers**\n",
    "\n",
    "1. ...\n",
    "1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.1.3. Learning rate\n",
    "\n",
    "We want to test the effect of learning rate on training convergence. This is why we trained identical models with different learning rates and then plotted the cost history for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITMAX  = 100\n",
    "alphas = [1., 0.1, 0.01, 0.001]\n",
    "\n",
    "classes = np.unique(Ygrades)\n",
    "\n",
    "# For each training rate, we train a separate model\n",
    "for alpha in alphas:\n",
    "    # Create a new logistic regression model\n",
    "    mdl = SGDClassifier(penalty=None, \n",
    "                        warm_start=True, \n",
    "                        loss='log_loss', \n",
    "                        learning_rate='constant', \n",
    "                        eta0=alpha,\n",
    "                        shuffle=False\n",
    "                        )\n",
    "    costs = []\n",
    "    for it in range(ITMAX):\n",
    "        # train the model\n",
    "        mdl.partial_fit(Xgrades_norm, Ygrades, classes=classes)\n",
    "        costs.append(log_loss(Ygrades, mdl.predict(Xgrades_norm)))\n",
    "        \n",
    "    # Visualization\n",
    "    plt.plot(costs, label = 'alpha=' + str(alpha))\n",
    "    \n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.legend()\n",
    "#plt.autoscale()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyze the results**\n",
    "\n",
    "We note that the model converges fast when alpha=0.1. In fact, it converges around iteration 15. When alpha is smaller, the model takes more iterations to converge. For example, the model with alpha=1.0 didn't converge even after 100 iterations.\n",
    "\n",
    "**Hypothesis:** a larger learning rate can lead to faster convergence \n",
    "\n",
    "1. Justify this hypothesis.\n",
    "1. Why we don't use a learning rate of 1 with just one iteration?\n",
    "1. Why we don't use a learning rate of 1 or more with manye iterations?\n",
    "\n",
    "**Answer**\n",
    "1. ...\n",
    "1. ...\n",
    "1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2. Multi-class Logistic Regression \n",
    "\n",
    "We want to compare some methods for Multi-class Logistic Regression:\n",
    "- Maximum entropy (MaxEnt)\n",
    "- One-vs-Rest  (OvR)\n",
    "- One-vs-One  (OvO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://goshippo.com/blog/measure-real-size-any-python-object/\n",
    "# This function will be used to get the size of a trained model\n",
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively finds size of objects\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Important mark as seen *before* entering recursion to gracefully handle\n",
    "    # self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([get_size(v, seen) for v in obj.values()])\n",
    "        size += sum([get_size(k, seen) for k in obj.keys()])\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        size += get_size(obj.__dict__, seen)\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([get_size(i, seen) for i in obj])\n",
    "    return size\n",
    "\n",
    "get_size({'first': 0.21, 'second': 'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to facilitate testing multiple models\n",
    "# it depends on global variables: Xbody_train, Ybody_train, Xbody_test, Ybody_test\n",
    "def multi_eval(mdls, X_trn=Xbody_train, Y_trn=Ybody_train, X_tst=Xbody_test, Y_tst=Ybody_test): \n",
    "    # performance metrics\n",
    "    perf = {\n",
    "        'trn_time': [],\n",
    "        'tst_time': [],\n",
    "        'trn_acc' : [],\n",
    "        'tst_acc' : [],\n",
    "        'size'    : [],\n",
    "    }\n",
    "    \n",
    "    for mdl in mdls:\n",
    "        start_time = timeit.default_timer()\n",
    "        mdl.fit(X_trn, Y_trn)\n",
    "        perf['trn_time'].append(timeit.default_timer() - start_time)\n",
    "    \n",
    "        Y_pred = mdl.predict(X_trn)\n",
    "        perf['trn_acc'].append(accuracy_score(Y_trn, Y_pred))\n",
    "    \n",
    "        start_time = timeit.default_timer()\n",
    "        Y_pred = mdl.predict(X_tst)\n",
    "        perf['tst_time'].append(timeit.default_timer() - start_time)\n",
    "        perf['tst_acc'].append(accuracy_score(Y_tst, Y_pred))\n",
    "        \n",
    "        perf['size'].append(get_size(mdl))\n",
    "        \n",
    "    return perf\n",
    "    \n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.2.1. OvR vs. MaxEnt\n",
    "\n",
    "We want to compare OvR and MaxEnt based on accuracy. We know that the models are almost identical in term of parameters size. The difference:\n",
    "\n",
    "| Model   |      OvR      |  MaxEnt |\n",
    "| :--- |:---|:---|\n",
    "| Activation function |  Logistic | Softmax |\n",
    "| Cost function |  Binary cross entropy   | Cross entropy |\n",
    "| Estimation | Majority vote | Maximal probability |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_jobs: use just one CPU core\n",
    "ovr     = LogisticRegression(n_jobs=1, max_iter=200, solver='lbfgs', penalty=None, multi_class='ovr'        )\n",
    "maxent  = LogisticRegression(n_jobs=1, max_iter=200, solver='lbfgs', penalty=None, multi_class='multinomial')\n",
    "# ovrP     = LogisticRegression(n_jobs=2, max_iter=200, solver='lbfgs', penalty=None, multi_class='ovr'        )\n",
    "# maxentP  = LogisticRegression(n_jobs=2, max_iter=200, solver='lbfgs', penalty=None, multi_class='multinomial')\n",
    "\n",
    "perf = multi_eval([ovr, maxent]) # [ovr, maxent, ovrP, maxentP]\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Algorithm'     : ['OvR', 'MaxEnt'], # ['OvR', 'MaxEnt', 'OvRP', 'MaxEntP']\n",
    "    'Size'          : perf['size'     ],\n",
    "    'Train time'    : perf['trn_time' ],\n",
    "    'Test time'     : perf['tst_time' ],\n",
    "    'Train Accuracy': perf['trn_acc'  ],\n",
    "    'Test Accuracy' : perf['tst_acc'  ],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyze the results**\n",
    "\n",
    "We note that the size, train time, test time are almost the same. \n",
    "\n",
    "As for the accuracy (train and test), MaXent has better quality than OvR.\n",
    "\n",
    "1. Why (based on the boundary decision hyperplane/decision mechanism)?\n",
    "1. Why (based on parameters update manner)?\n",
    "\n",
    "**Answer**\n",
    "1. ...\n",
    "1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.2.3. OvR vs. OvO\n",
    "\n",
    "We want to compare OvR and OvO using logistic regression. \n",
    "We duplicated the data so we will have many samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REP = 100\n",
    "\n",
    "Xbody_trainM = np.repeat(Xbody_train, REP, axis=0)\n",
    "Ybody_trainM = np.repeat(Ybody_train, REP, axis=0)\n",
    "Xbody_testM = np.repeat(Xbody_test, REP, axis=0)\n",
    "Ybody_testM = np.repeat(Ybody_test, REP, axis=0)\n",
    "\n",
    "ovr_seq = OneVsRestClassifier(LogisticRegression(solver='lbfgs', max_iter=100, penalty=None, n_jobs=1), n_jobs=1)\n",
    "ovo_seq = OneVsOneClassifier (LogisticRegression(solver='lbfgs', max_iter=100, penalty=None, n_jobs=1), n_jobs=1)\n",
    "ovr_con = OneVsRestClassifier(LogisticRegression(solver='lbfgs', max_iter=100, penalty=None, n_jobs=1), n_jobs=-1)\n",
    "ovo_con = OneVsOneClassifier (LogisticRegression(solver='lbfgs', max_iter=100, penalty=None, n_jobs=1), n_jobs=-1)\n",
    "\n",
    "\n",
    "perf = multi_eval([ovr_seq, ovo_seq, ovr_con, ovo_con], \n",
    "                  X_trn=Xbody_trainM, \n",
    "                  Y_trn=Ybody_trainM, \n",
    "                  X_tst=Xbody_testM, \n",
    "                  Y_tst=Ybody_testM)\n",
    "# multi_eval(mdls, X_trn=Xbody_trainM, Y_trn=Ybody_trainM, X_tst=Xbody_testM, Y_tst=Ybody_testM)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Algorithm'     : ['Sequential OvR', 'Sequential OvO', 'Concurrent OvR', 'Concurrent OvO'],\n",
    "    'Size'          : perf['size'     ],\n",
    "    'Train time'    : perf['trn_time' ],\n",
    "    'Test time'     : perf['tst_time' ],\n",
    "    'Train Accuracy': perf['trn_acc'  ],\n",
    "    'Test Accuracy' : perf['tst_acc'  ],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyze the results**\n",
    "\n",
    "1. Why the size of OvO is greater than OvR's?\n",
    "1. Why OvO takes less time to train than OvR?\n",
    "1. Why OvO takes more time to test than OvR?\n",
    "1. Why OvO generalizes better than OvR?\n",
    "1. How to modify OvR for multi-label classification? \n",
    "1. How to modify OvO for multi-label classification?\n",
    "\n",
    "**Answer**\n",
    "1. ...\n",
    "1. ...\n",
    "1. ...\n",
    "1. ...\n",
    "1. ...\n",
    "1. ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'END OF LAB ...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
